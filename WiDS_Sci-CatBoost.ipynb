{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Women in Data Science - 2018 - Kaggle/Stanford Uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Clean and Transform dataset for use with sklearn and tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/train.csv\", low_memory=False)\n",
    "df_test = pd.read_csv(\"Data/test.csv\", low_memory=False)\n",
    "df_dict = pd.read_csv('Data/WiDS data dictionary v2.csv')\n",
    "test_id = df_test['test_id']\n",
    "\n",
    "Y = df['is_female'] # Label\n",
    "X = df.drop(['train_id'], axis = 1)\n",
    "X = X.dropna(axis=1, how='all') # If all values are nans, drop col\n",
    "X = X.replace(to_replace=[99,99.0],value=[np.NaN,np.NaN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(X):\n",
    "    '''\n",
    "\n",
    "    Returns a dictionary object with dummified categorical variables and standardized numerical variables.\n",
    "\n",
    "    1. Check data dictionary to see which variables are numerical/categorical\n",
    "\n",
    "    - Get a tentative list of numerical and categorical variables:\n",
    "    - For categorical vars, a starting point is all variables that do not have the dtype 'np.number'\n",
    "    - Final list of column names is stored as 'treat_as_num' and 'treat_as_cat'.\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    # For storage of column names that are categorical / numerical\n",
    "    treat_as_num = []\n",
    "    treat_as_cat = []\n",
    "\n",
    "    tentative_num = [i for i in df_dict[df_dict['Values'] == 'N/A\\n99=DK']['Column Name'].values if i in X.columns.values]\n",
    "    tentative_cat = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "    treat_as_num = treat_as_num + tentative_num[:]\n",
    "    treat_as_cat = treat_as_cat + tentative_cat[:]\n",
    "\n",
    "    ### Drop columns that are 90% missing values\n",
    "    for i in X.columns:\n",
    "        if sum(X[i].isnull()) > 14604:\n",
    "            if sum(X[i].value_counts()) < 400:\n",
    "                X.drop(i,inplace=True,axis=1)\n",
    "\n",
    "\n",
    "    ### Columns that are in both the df and data dictionary.\n",
    "    cols_in_df_and_datadict = [i for i in X.columns.values if i in df_dict['Column Name'].values]\n",
    "\n",
    "    ### Columns that are NOT in the data dictionary but are found in the df.\n",
    "    cols_not_in_dict = [i for i in X.columns.values if i not in df_dict['Column Name'].values]\n",
    "\n",
    "    for col in cols_not_in_dict:\n",
    "\n",
    "        num_of_categories = len(X[col].value_counts().keys())\n",
    "\n",
    "        if col in treat_as_cat:\n",
    "            pass\n",
    "        elif num_of_categories >= 10:\n",
    "            treat_as_num.append(col)\n",
    "        elif num_of_categories <= 10:\n",
    "            treat_as_cat.append(col)\n",
    "\n",
    "    ####\n",
    "\n",
    "    for col in cols_in_df_and_datadict:\n",
    "\n",
    "        if col in treat_as_num:\n",
    "            pass\n",
    "\n",
    "        elif col in treat_as_cat:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            treat_as_cat.append(col)\n",
    "\n",
    "\n",
    "    ####\n",
    "    \n",
    "    data_dict = {} \n",
    "\n",
    "    for i in X.columns:\n",
    "\n",
    "        if i in treat_as_cat: # For every column, if categorical, convert to one hot encoding/dummy vars\n",
    "            \n",
    "            #for row in X[i].iteritems():\n",
    "                \n",
    "            #    if np.isnan(row[1]):\n",
    "                    \n",
    "            #        if X.loc[row[0],'is_female'] == 0:\n",
    "            #            X.set_value(row[0],i,X[X['is_female'] == 0][i].mode()) \n",
    "                \n",
    "            #        elif X.loc[row[0],'is_female'] == 1:\n",
    "            #            X.set_value(row[0],i,X[X['is_female'] == 1][i].mode())\n",
    "\n",
    "            sub_dummy = pd.get_dummies(X[i],prefix=i,dummy_na=False)\n",
    "\n",
    "            for j in sub_dummy.columns.values: # For every column in dummified df, add to data_dict\n",
    "                data_dict[j] = sub_dummy[j].values\n",
    "\n",
    "        else: # If col is numerical, standardize, fill \n",
    "\n",
    "            X[i].fillna(X[i].median(),inplace=True)\n",
    "            stdized_col = (X[i] - X[i].mean() )/ X[i].std()\n",
    "            data_dict[i] = stdized_col.values\n",
    "            \n",
    "    data_dict.pop('is_female',None)\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame.from_dict(preprocess(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['test_id'], axis = 1)\n",
    "df_test = df_test.dropna(axis=1, how='all') # If all values are nans, drop col\n",
    "df_test = df_test.replace(to_replace=[99,99.0],value=[np.NaN,np.NaN])\n",
    "X_test = pd.DataFrame.from_dict(preprocess(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test[[i for i in X_test.columns.values if i in X.columns.values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[[i for i in X_test.columns.values if i in X.columns.values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=50, learning_rate=0.5, depth=10,\\\n",
    "                       custom_metric='AUC',eval_metric='AUC',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get predicted classes\n",
    "preds_class = model.predict(x_val)\n",
    "# Get predicted probabilities for each class\n",
    "preds_proba = model.predict_proba(x_val)\n",
    "# Get predicted RawFormulaVal\n",
    "#preds_raw = model.predict(test_data, prediction_type='RawFormulaVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_val,preds_class))\n",
    "print(roc_auc_score(y_val,[i[1] for i in preds_proba]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best scoring model uptill now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in [0.3,0.32,0.35,0.38]:\n",
    "    \n",
    "    for j in [5,7,11]:\n",
    "        \n",
    "        for x in [100,300,500,1000,1500,2000]:\n",
    "                \n",
    "                x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "                print('\\n','Learning Rate : ' , i , ' Max Depth : ', j, ' Iterations : ', x)\n",
    "\n",
    "                model = CatBoostClassifier(iterations=x, learning_rate=i, depth=j,\\\n",
    "                                           custom_metric='AUC',eval_metric='AUC',logging_level='Silent')\n",
    "\n",
    "                model.fit(x_train.values, y_train.values)\n",
    "\n",
    "                # Get predicted classes\n",
    "                preds_class = model.predict(x_val)\n",
    "                # Get predicted probabilities for each class\n",
    "                preds_proba = model.predict_proba(x_val)\n",
    "                print(accuracy_score(y_val,preds_class))\n",
    "                print(roc_auc_score(y_val,[i[1] for i in preds_proba]))\n",
    "                \n",
    "                \n",
    "                preds_proba_test = model.predict_proba(X_test)\n",
    "                current = [i[1] for i in preds_proba_test]\n",
    "                results.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg = pd.DataFrame(results)\n",
    "avg = avg.mean(axis=0)\n",
    "pd.DataFrame(avg,columns=['is_female'],index=test_id).to_csv('catboost_avg.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### More Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Avg of various RandomForest models\n",
    "results_rf = []\n",
    "\n",
    "for j in [2,5,7,11,None]:\n",
    "\n",
    "    for x in [100,500,1500]:\n",
    "\n",
    "            x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "            print(' Max Depth : ', j, ' Iterations : ', x)\n",
    "\n",
    "            model = RandomForestClassifier(n_estimators=x,\n",
    "                                           max_features='auto',\n",
    "                                           max_depth=j,\n",
    "                                           n_jobs=-1,\n",
    "                                           random_state=1,\n",
    "                                           criterion='gini',\n",
    "                                           oob_score=True,\n",
    "                                           bootstrap=True,\n",
    "                                           )\n",
    "\n",
    "            model.fit(x_train.values, y_train.values)\n",
    "\n",
    "            # Get predicted classes\n",
    "            preds_class = model.predict(x_val)\n",
    "            # Get predicted probabilities for each class\n",
    "            preds_proba = model.predict_proba(x_val)\n",
    "            print(accuracy_score(y_val,preds_class))\n",
    "            print(roc_auc_score(y_val,[i[1] for i in preds_proba]))\n",
    "\n",
    "\n",
    "            preds_proba_test = model.predict_proba(X_test)\n",
    "            current = [i[1] for i in preds_proba_test]\n",
    "            results_rf.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg = pd.DataFrame(results_rf)\n",
    "avg = avg.mean(axis=0)\n",
    "pd.DataFrame(avg,columns=['is_female'],index=test_id).to_csv('rf_avg.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = GradientBoostingClassifier(n_estimators=1500, learning_rate=0.32,loss='exponential', max_depth=11,random_state=0)\n",
    "clf3 = SVC(kernel='rbf', probability=True, random_state=0, verbose=True)\n",
    "clf4 = RandomForestClassifier(n_estimators=250)\n",
    "clf5 = AdaBoostClassifier(n_estimators=1100,learning_rate=0.82)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('gbc', clf2), ('svc', clf3), ('rf',clf4), ('ada',clf5)], voting='soft')\n",
    "\n",
    "clf1 = clf1.fit(X,Y)\n",
    "clf2 = clf2.fit(X,Y)\n",
    "clf3 = clf3.fit(X,Y)\n",
    "clf4 = clf4.fit(X,Y)\n",
    "clf5 = clf5.fit(X,Y)\n",
    "\n",
    "eclf = eclf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_test = eclf.predict_proba(X_test)\n",
    "pred_prob_test = [i[1] for i in pred_prob_test]\n",
    "pd.DataFrame(pred_prob_test,columns=['is_female'],index=test_id).to_csv('Voting_Classifier_1.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = DecisionTreeClassifier(max_depth=None,)\n",
    "clf2 = GradientBoostingClassifier(n_estimators=1500, learning_rate=0.32,loss='exponential', max_depth=11,random_state=0)\n",
    "clf3 = SVC(kernel='rbf', probability=True, random_state=0, verbose=True)\n",
    "clf4 = RandomForestClassifier(n_estimators=250)\n",
    "clf5 = AdaBoostClassifier(n_estimators=1100,learning_rate=0.82)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('gbc', clf2), ('svc', clf3), ('rf',clf4), ('ada',clf5)],\\\n",
    "                        voting='soft',weights=[1,2,1,1,1],n_jobs=-1)\n",
    "\n",
    "clf1 = clf1.fit(X,Y)\n",
    "clf2 = clf2.fit(X,Y)\n",
    "clf3 = clf3.fit(X,Y)\n",
    "clf4 = clf4.fit(X,Y)\n",
    "clf5 = clf5.fit(X,Y)\n",
    "\n",
    "eclf = eclf.fit(X,Y)\n",
    "\n",
    "pred_prob_test = eclf.predict_proba(X_test)\n",
    "pred_prob_test = [i[1] for i in pred_prob_test]\n",
    "pd.DataFrame(pred_prob_test,columns=['is_female'],index=test_id).to_csv('Voting_Classifier_2.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = CatBoostClassifier(iterations=300,max_depth=5,learning_rate=0.38,custom_metric='AUC',eval_metric='AUC')\n",
    "clf2 = GradientBoostingClassifier(n_estimators=1500, learning_rate=0.32,loss='exponential', max_depth=11,random_state=0)\n",
    "clf3 = SVC(kernel='rbf', probability=True, random_state=0, verbose=True)\n",
    "clf4 = RandomForestClassifier(n_estimators=250)\n",
    "clf5 = AdaBoostClassifier(n_estimators=1100,learning_rate=0.82)\n",
    "clf6 = CatBoostClassifier(iterations=100,max_depth=7,learning_rate=0.38,custom_metric='AUC',eval_metric='AUC')\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('cat', clf1), ('gbc', clf2), ('svc', clf3), ('rf',clf4), ('ada',clf5),('cat2',clf6)],\\\n",
    "                        voting='soft',weights=[2,2,1,1,1,2],n_jobs=-1)\n",
    "\n",
    "clf1 = clf1.fit(X,Y)\n",
    "clf2 = clf2.fit(X,Y)\n",
    "clf3 = clf3.fit(X,Y)\n",
    "clf4 = clf4.fit(X,Y)\n",
    "clf5 = clf5.fit(X,Y)\n",
    "clf6 = clf6.fit(X,Y)\n",
    "eclf = eclf.fit(X,Y)\n",
    "\n",
    "pred_prob_test = eclf.predict_proba(X_test)\n",
    "pred_prob_test = [i[1] for i in pred_prob_test]\n",
    "pd.DataFrame(pred_prob_test,columns=['is_female'],index=test_id).to_csv('Voting_Classifier_3.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = CatBoostClassifier(iterations=300,max_depth=5,learning_rate=0.38,custom_metric='AUC',eval_metric='AUC',random_state=1)\n",
    "clf2 = GradientBoostingClassifier(n_estimators=1500, learning_rate=0.32,loss='exponential', max_depth=11,random_state=1)\n",
    "clf3 = SVC(kernel='rbf', probability=True, random_state=1, verbose=True)\n",
    "clf4 = RandomForestClassifier(n_estimators=250,random_state=1,)\n",
    "clf5 = AdaBoostClassifier(n_estimators=1100,learning_rate=0.82,random_state=1)\n",
    "clf6 = CatBoostClassifier(iterations=100,max_depth=7,learning_rate=0.35,custom_metric='AUC',eval_metric='AUC',random_state=1,)\n",
    "clf7 = CatBoostClassifier(iterations=500,max_depth=5,learning_rate=0.3,custom_metric='AUC',eval_metric='AUC',random_state=1,)\n",
    "clf8 = CatBoostClassifier(iterations=1000,max_depth=3,learning_rate=0.32,custom_metric='AUC',eval_metric='AUC',random_state=1,)\n",
    "clf9 = GradientBoostingClassifier(n_estimators=500, learning_rate=0.3,loss='exponential', max_depth=5,random_state=1)\n",
    "clf10 = GaussianNB()\n",
    "clf11 = LogisticRegression(penalty='l2',tol=0.1,random_state=1)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('cat', clf1), ('gbc', clf2), ('svc', clf3),\\\n",
    "                                    ('rf',clf4), ('ada',clf5),('cat2',clf6),\\\n",
    "                                    ('cat3',clf7),('cat4',clf8),('gbc2',clf9),('gnb',clf10),('lgr',clf11),],\n",
    "                        voting='soft',weights=[1.35, 1.35, 1.25, 1, 1, 1.15, 1.15, 1.15, 1.10, 1, 1.15],n_jobs=-1)\n",
    "\n",
    "clf1 = clf1.fit(X,Y)\n",
    "clf2 = clf2.fit(X,Y)\n",
    "clf3 = clf3.fit(X,Y)\n",
    "clf4 = clf4.fit(X,Y)\n",
    "clf5 = clf5.fit(X,Y)\n",
    "clf6 = clf6.fit(X,Y)\n",
    "clf7 = clf7.fit(X,Y)\n",
    "clf8 = clf8.fit(X,Y)\n",
    "clf9 = clf9.fit(X,Y)\n",
    "clf10 = clf10.fit(X,Y)\n",
    "clf11 = clf11.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_pred = []\n",
    "for M in [clf1,clf2,clf3,clf4,clf5,clf6,clf7,clf8,clf9,clf10,clf11]:\n",
    "    \n",
    "    pred_prob_test = M.predict_proba(X_test)\n",
    "    pred_prob_test = [i[1] for i in pred_prob_test]\n",
    "    avg_pred.append(pred_prob_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_pred = pd.DataFrame(avg_pred)\n",
    "avg_pred = avg_pred.mean(axis=0)\n",
    "pd.DataFrame(avg,columns=['is_female'],index=test_id).to_csv('11_avg_models.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = CatBoostClassifier(iterations=300,max_depth=5,learning_rate=0.38,custom_metric='AUC',eval_metric='AUC',random_state=1)\n",
    "clf2 = GradientBoostingClassifier(n_estimators=1500, learning_rate=0.32,loss='exponential', max_depth=11,random_state=1)\n",
    "clf3 = SVC(kernel='rbf', probability=True, random_state=1, verbose=True)\n",
    "clf4 = RandomForestClassifier(n_estimators=250,random_state=1,)\n",
    "clf5 = AdaBoostClassifier(n_estimators=1100,learning_rate=0.82,random_state=1)\n",
    "clf6 = CatBoostClassifier(iterations=100,max_depth=7,learning_rate=0.35,custom_metric='AUC',eval_metric='AUC',random_state=1,)\n",
    "clf7 = CatBoostClassifier(iterations=500,max_depth=5,learning_rate=0.3,custom_metric='AUC',eval_metric='AUC',random_state=1,)\n",
    "clf8 = CatBoostClassifier(iterations=1000,max_depth=3,learning_rate=0.32,custom_metric='AUC',eval_metric='AUC',random_state=1,)\n",
    "clf9 = GradientBoostingClassifier(n_estimators=500, learning_rate=0.3,loss='exponential', max_depth=5,random_state=1)\n",
    "clf10 = GaussianNB()\n",
    "clf11 = LogisticRegression(penalty='l2',tol=0.1,random_state=1)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('cat', clf1), ('gbc', clf2), ('svc', clf3),\\\n",
    "                                    ('rf',clf4), ('ada',clf5),('cat2',clf6),\\\n",
    "                                    ('cat3',clf7),('cat4',clf8),('gbc2',clf9),('gnb',clf10),('lgr',clf11),],\n",
    "                        voting='soft',weights=[1.35, 1.35, 1.25, 1, 1, 1.15, 1.15, 1.15, 1.10, 1, 1.15],n_jobs=-1)\n",
    "\n",
    "clf1 = clf1.fit(X,Y)\n",
    "clf2 = clf2.fit(X,Y)\n",
    "clf3 = clf3.fit(X,Y)\n",
    "clf4 = clf4.fit(X,Y)\n",
    "clf5 = clf5.fit(X,Y)\n",
    "clf6 = clf6.fit(X,Y)\n",
    "clf7 = clf7.fit(X,Y)\n",
    "clf8 = clf8.fit(X,Y)\n",
    "clf9 = clf9.fit(X,Y)\n",
    "clf10 = clf10.fit(X,Y)\n",
    "clf11 = clf11.fit(X,Y)\n",
    "\n",
    "eclf = eclf.fit(X,Y)\n",
    "\n",
    "pred_prob_test = eclf.predict_proba(X_test)\n",
    "pred_prob_test = [i[1] for i in pred_prob_test]\n",
    "pd.DataFrame(pred_prob_test,columns=['is_female'],index=test_id).to_csv('Voting_Classifier_4.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = eclf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob = [i[1] for i in pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_prob,columns=['is_female'],index=test_id).to_csv('Voting_Classifier_4.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
